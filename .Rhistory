round(importance(mod4), 2)
?varlmp
??varlmp
varlmp(mod4)
varImp(mod4)
mod4<- randomForest(y ~ ., data=vowel.train, importance=0,proximity=TRUE)
varImp(mod4)
mod4<- randomForest(y ~ ., data=vowel.train, importance=2,proximity=TRUE)
varImp(mod4)
mod4<- randomForest(y ~ ., data=vowel.train, imp=2)
varImp(mod4)
mod4<- randomForest(y ~ ., data=vowel.train, imp=1)
varImp(mod4)
mod4<- randomForest(y ~ ., data=vowel.train, imp=0)
varImp(mod4)
order(varImp(mod4))
library(ISLR);data(Wage);library(ggplot2);library(caret);
Wage <- subset(Wage,select = -c(logwage))
head(Wagee)
head(Wage)
dim(Wage)
Wage <- subset(Wage,select = -c(logwage))
inBuild <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
validation <- Wage[-inBuild,]
buildData <-Wage[inBuild]
inTrain <- createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
training <- buildData[inTrain]
testing <-buildData[-inTrain]
Wage <- subset(Wage,select = -c(logwage))
names(Wage)
inBuild <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
validation <- Wage[-inBuild,]
buildData <-Wage[inBuild]
inTrain <- createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
buildData <-Wage[inBuild,]
inTrain <- createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
training <- buildData[inTrain]
testing <-buildData[-inTrain]
dim(training)
dimtraining
dim(training)
head(training)
training
buildData
names(buildData)
buildData <-Wage[inBuild,]
inTrain <- createDataPartition(y=buildData$wage,p=0.7,list=FALSE)
head(inTrain)
training <- buildData[inTrain,]
testing <-buildData[-inTrain,]
dim(training)
dim(testing)
dim(validation)
mod1 <-train(wage~.,method="glm",data=training)
mod2 <-train(wage~.,method="rf",data=training,trControl = trainControl(method = "cv"),number=3)
mod1
pred1 <- predict(mod1,testing)
pred2 <- predict(mod2,testing)
qplot(pred1,pred2,bolour=wage,data=testing)
names(testing)
pred1 <- predict(mod1,testing)
pred2 <- predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data=testing)
predDF <- data.frame(pred1,pred2,wage=testing$wage)
head(preDF)
head(predDF)
comModFit <- train(wage~.method ='gam',data=predDF)
comModFit <- train(wage~.method='gam',data=predDF)
comModFit <- train(wage~.,method='gam',data=predDF)
install.packages("mgcv")
install.packages("mgcv")
install.packages("mgcv")
install.packages("mgcv")
comModFit <- train(wage~.,method='gam',data=predDF)
library(ISLR);data(Wage);library(ggplot2);library(caret);
comModFit <- train(wage~.,method='gam',data=predDF)
comModFit <- train(wage~.,method='glm',data=predDF)
comPred <- predict(comModFit,predDF)
sqrt(sum(pred1-testing$wage)^2)
sqrt(sum(pred1-testing$wage)^2))
sqrt(sum(pred1-testing$wage)^2)
sqrt(sum(pred2-testing$wage)^2)
pred1 <- predict(mod1,testing)
sqrt(sum(pred1-testing$wage)^2)
mod1 <-train(wage~.,method="glm",data=training)
pred1 <- predict(mod1,testing)
sqrt(sum(pred1-testing$wage)^2)
sqrt(sum(combPred-testing$wage)^2)
sqrt(sum(comPred-testing$wage)^2)
install.packages("quantmod")
library("quantmod");
from.dat <- as.Date('01/01/08', format = '%m/%d/%y')
from.dat
to.dat <- as.Data('12/31/13', format='%m/%d/%y')
to.dat <- as.Date('12/31/13', format='%m/%d/%y')
getSymbols("GOOG", src = 'google', from = from.dat, to = to.dat)
getSymbols("GOOG", src = 'google', from = from.dat, to = to.dat)
getwd()
GOOG <- read.csv('goog.csv')
head(GOOG)
mGoog <- to.monthly(GOOG)
as.xts(GOOG)
as.xts(GOOG$Date)
class(GOOG$Date)
as.Date(GOOG$Date)
data(iris);library(ggplot2)
data(iris);library(ggplot2)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
kMeans1 <- kmeans(subset(training,select = -c(Species)), centers=3)
subset(training,select = -c(Species))
head(training)
ss<-subset(training,select = -c(Species))
head(ss)
kmeans(ss, centers=3)
ss[is.na(ss)]<-0
kmeans(ss, centers=3)
kMeans1 <- kmeans(ss, centers=3)
training$clusters <- as.factor(kMeeans1$cluster)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length, colour=clusters,data=training)
kMeans1 <- kmeans(ss, centers=5)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length, colour=clusters,data=training)
kMeans1 <- kmeans(ss, centers=3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length, colour=clusters,data=training)
table(kMeasn1$cluster, training$Species)
table(kMean1$cluster, training$Species)
table(kMeans1$cluster, training$Species)
modFit <- train(clusters ~., data=ss,method ='rpart')
table(predict(modFit,training),training$Species)
library(caret)
modFit <- train(clusters ~., data=ss,method ='rpart')
head(ss)
modFit <- train(clusters ~., data=training,method ='rpart')
names(training)
str(training)
list(training$clusters)
training[is.na(training)] <- 0
modFit <- train(clusters ~., data=training,method ='rpart')
na.exclude(training)
training<-na.exclude(training)
names(training)
modFit <- train(clusters ~., data=training,method ='rpart')
library(rpart)
modFit <- train(clusters ~., data=training,method ='rpart')
library(AppliedPredictiveModeling)
?AppliedPredictiveModeling
install.packages(AppliedPredictiveModeling)
install.packages('AppliedPredictiveModeling')
install.packages("AppliedPredictiveModeling")
?AppliedPredictiveModeling
library(AppliedPredictiveModeling)
?AppliedPredictiveModeling
library(caret)
?caret
??caret
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(gbm)
library(lubridate)
library(forecast)
library(e1071)
install.packages('forecast')
library(forecast)
?accuracy
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.vowel$y<-as.factor(vowel.vowel$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
rf_mod <- train(y~., data=vowel.traing,method='rf',prox=TRUE)
rf_mod <- train(y~., data=vowel.train,method='rf',prox=TRUE)
rf_outcome <- predict(rf_mod,vowel.test)
head(rf_outcome)
rf_accuracy <- length(rf_outcome == voweel.test$y)/length(voweel.test$y)
rf_accuracy <- length(rf_outcome == vowel.test$y)/length(vowel.test$y)
rf_accuracy
length(rf_outcome == vowel.test$y)
length(vowel.test$y)
length(rf_outcome[rf_outcome== vowel.test$y])
rf_accuracy <- length(rf_outcome[rf_outcome== vowel.test$y])/length(vowel.test$y)
rf_accuracy
gbm_mod <-train(y~., method="gbm", data=vowel.train, verbose=FALSE)
gbm_mod <-train(y~., method="gbm", data=vowel.train, verbose=FALSE)
install.packages('gbm')
install.packages("gbm")
gbm_mod <-train(y~., method="gbm", data=vowel.train, verbose=FALSE)
library(caret)
gbm_mod <-train(y~., method="gbm", data=vowel.train, verbose=FALSE)
gbm_mod <-train(y~., method="gbm", data=vowel.train)
library(gbm)
library(gbm)
gbm_mod <-train(y~., method="gbm", data=vowel.train, verbose=FALSE)
gbm_outcome <- predict(gbm_mod,vowel.test)
gbm_accuracy <- length(gbm_outcome[gbm_outcome== vowel.test$y])/length(vowel.test$y)
gbm_accuracy
vowel.test[(gbm_outcome== vowel.test$y)&(rf_outcome== vowel.test$y)]
gbm_index <- gbm_outcome== vowel.test$y
head(gbm_index)
rf_index <- rf_outcome== vowel.test$y
rf_index$gbm_index
rf_index$$gbm_index
rf_index&gbm_index
vowel.test[rf_index&gbm_index]
vowel.test$y[rf_index&gbm_index]
length(vowel.test$y[rf_index&gbm_index])/length(vowel.test$y)
length(vowel.test$y[rf_index|gbm_index])/length(vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf_mod <- train(diagnosis~., data=training, method='rf',prox=TRUE)
rf_outcome <- predict(rf_mod,testing)
gbm_mod <- train(diagnosis~., data=training, method='gbm',prox=TRUE)
gbm_outcome <- predict(gbm_mod,testing)
head(training)
gbm_mod <- train(diagnosis~., data=training, method='gbm',verbose=FALSE)
gbm_outcome <- predict(gbm_mod,testing)
lda_mod <- train(diagnosis~., data=training, method='lda')
lda_outcome <- predict(lda_mod,testing)
combine_df <- data.frame(rf_outcome,gbm_outcome,lda_outcome,diagnosis= testing$diagnosis )
combine_mod <- train(diagnosis~., method='rf', data=combine_df, prox=TRUE)
combine_outcome <- predict(combine_mod, combine_df)
combine_accuracy<-length(combine_outcome[combine_outcome==testing$diagnosis])/length(testing$diagnosis)
combine_accuracy
gbm_accuracy<-length(bgm_outcome[gbm_outcome==testing$diagnosis])/length(testing$diagnosis)
gbm_accuracy<-length(gbm_outcome[gbm_outcome==testing$diagnosis])/length(testing$diagnosis)
gbm_accuracy
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(training)
?lasso
??lasso
?plot.enet
??plot.eneet
??plot.enet
?plot.enet
ga_mod <- train(CompressiveStrength~., data=training, method='gasso')
?gasso
??gasso
install.packages(gasso)
install.packages('gasso')
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
la_mod <- train(CompressiveStrength~., data=training, method='lasso')
library(elasticnet)
la_mod
la_mod$finalModel
plot.enet(la_mod$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate)
getwd()
dat = read.csv("~/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library("forecast")
?bats
?forecast
dim(testing)
dim(testing)[1]
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
fcast
str(tstrain)
head(tstrain)
tstrain[100:110]
class(tstrain)
fcast$lower
fcast$lower < testing$visitsTumblr
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testin
testing = concrete[ -inTrain,]
set.seed(325)
install.packages(e1071)
install.packages('e1071')
install.packages("e1071")
library(e1071)
?e1071
??e1071
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf_mod <- train(diagnosis~., data=training, method='rf',prox=TRUE)
rf_outcome <- predict(rf_mod,testing)
gbm_mod <- train(diagnosis~., data=training, method='gbm',verbose=FALSE)
gbm_outcome <- predict(gbm_mod,testing)
lda_mod <- train(diagnosis~., data=training, method='lda')
lda_outcome <- predict(lda_mod,testing)
combine_df <- data.frame(rf_outcome,gbm_outcome,lda_outcome,diagnosis= testing$diagnosis )
combine_mod <- train(diagnosis~., method='rf', data=combine_df, prox=TRUE)
combine_outcome <- predict(combine_mod, combine_df)
combine_accuracy<-length(combine_outcome[combine_outcome==testing$diagnosis])/length(testing$diagnosis)
confusionMatrix(combine_mod, testing$diagnosis)$overall[1]
confusionMatrix(combine_mod, testing$diagnosis)
confusionMatrix(combine_mod, testing$diagnosis)$overall
confusionMatrix(combine_mod, testing$diagnosis).overall
?confusionMatrix
confusionMatrix(combine_mod)
confusionMatrix(combine_outcome, testing$diagnosis)$overall[1]
combine_accuracy
getwd()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
Train_Data <- read.csv(pml-training)
Train_Data <- read.csv('pml-training')
Train_Data <- read.csv('pml-training.csv')
getwd()
setwd(/Users/freefrog/Studing/DataScience/Practical_ML)
setwd('/Users/freefrog/Studing/DataScience/Practical_ML')
Train_Data <- read.csv('pml-training.csv')
summary(Train_Data)
dim(Train_Data)
Test_Data <- read.csv('pml-testing.csv')
dim(Test_Data)
names(Train_Data)
names(Train_Data[,-1])
names(Train_Data[,-2])
names(Train_Data)
names(Train_Data[,1])
names(Train_Data[,10])
head(Train_Data[,10])
head(Train_Data[1,10])
head(Train_Data[,11])
head(Train_Data[,-1])
a<-data.frame(x=[1,2,3,4,5],y=[2,3,4,5,6],z=[3,4,5,6,7])
x=[1,2,3]
x=(1,2,3)
[1:10]
?data.frame()
a<-data.frame(x=1:5,y=2:6,z=3:7)
a
a[,-1]
class(a)
class(Train_Data)
Train_Data[1,1]
dim(Train_Data[,-1])
dim(Train_Data)
names(Train_Data[,-1])
names(Train_Data)
names(a)
names(a[,-1])
a[,-1]
names(Train[,-160])
names(Train_Data[,-160])
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
Train_Data <- read.csv('pml-training.csv')
Test_Data <- read.csv('pml-testing.csv')
?preProcess
Preprocess_Data <- preProcess(log10(Training_Data[,-160]+1),method="pca",pcaComp=2)
library(caret)
Preprocess_Data <- preProcess(log10(Training_Data[,-160]+1),method="pca",pcaComp=2)
inTrain <- createDataPartition(y=Train_Data$classe, p=0.75, list=FALSE)
Training_Data <- Train_Data[inTrain,]
Preprocess_Data <- preProcess(log10(Training_Data[,-160]+1),method="pca",pcaComp=2)
prc<-prcomp(log10(Training_Data[,-160]+1))
Training_Data[,-160
]
log10(Training_Data[,-160]+1)
class(Training_Data)
str(Training_Data)
preObj <- preProcess(Training_Data[,-160],method=c("boxCox"))
?preProcess
preObj <- preProcess(Training_Data[,-160],method=c("BoxCox"))
preObj
prepre<-predict(preObj,Training_Data[,-160])
prepre
dim(preepree)
dim(prepre)
dim(preObj)
preObj
args(preObj)
preObj$dim
preObj$numComp
preObj$bc
preObj$rotation
prc<-prcomp(Training_Data[,-160])
modelFit<-train(classe~. data=Training_Data, preProcess=c("pca"),method="glm")
modelFit<-train(classe~., data = Training_Data, preProcess=c('pca'),method="glm")
modelFit
modelFit<-train(classe~., data = Training_Data, preProcess=c('centere','scale'),method="glm")
modelFit
modelFit<-train(classe~., data = Training_Data, method="glm")
modelFit
preoutcome<-predict(modelFit, data = Training_Data)
plot(x=preoutcome, y=Training_Data$classe)
preoutcome
dim(Training_Data)
Training_Data$classe
modelFit<-train(classe~., data = Training_Data, preProcess=c('centere','scale'),method="glm")
modleFit
modelFit
names(Training_Data)
modelFit<-train(classe~., data = Training_Data, preProcess=c('center','scale'),method="glm")
modeelFit
modelFit
modelFit<-train(classe~.,method="glm")
modelFit<-train(classe~.,data = Training_Data,method="glm")
modelFit
Train_Data <- read.csv('pml-training.csv')
modelFit<-train(classe~.,data = Train_Data,method="glm")
modelFit
Test_Data <- read.csv('pml-testing.csv')
predict(modelFit,data=Train_Data)
sss<-predict(modelFit,data=Train_Data)
length(sss)
Train_Data$classe
length(Train_Data$classe)
names(Train_Data)
Train_Data$gyros_forearm_y
train(classe~gyros_forearm_y, data=Train_Data, method ='glm')
plot(Train_Data$classe,Train_Data$raw_timestamp_part_1)
plot(Train_Data$classe,Train_Data$stddev_roll_belt)
aaa<-train(classe~stddev_roll_belt,data=Train_Data,method = 'lm')
predict(aaa,data=Train_Data)
which(Train_Data=='spam')
which(Train_Data==1
)
cor(Train_Data[,-160])
Train_Data <- read.csv('pml-training.csv')
Test_Data <- read.csv('pml-testing.csv')
dim(Train_Data)
dim(Test_Data)
inTrain <- createDataPartition(y=Train_Data$classe, p=0.75, list=FALSE)
Training_Data <- Train_Data[inTrain,]
Validation_Data <- Train_Data[-inTrain,]
names(Training_Data)
str(Train_Data)
which
class(Training_Data)
class(Training_Data[:,1])
class(Training_Data[,1])
class(Training_Data[,2])
class(Training_Data[,1:160])
class(Training_Data[,1:2])
mod3<- train(classe~.,data=Train_Data,method='glm', family="binomial")
mod3
mod3<- train(classe~.,data=Train_Data,method='glm')
mod3
predict(mod3,data=Train_Data)
sss<-predict(mod3,data=Train_Data)
str(sss)
mod3
mod3$metric
mod3$method
mod3$coefnames
data(spam)
?train
mod3$finalModel
?train
model_data<-train(classe~.,data=Training_Data,method='glm')
na.exclude(Training_Data)
Train_Data<-na.exclude(Training_Data)
model_data<-train(classe~.,data=Training_Data,method='glm')
Training_Data<-na.exclude(Training_Data)
model_data<-train(classe~.,data=Training_Data,method='glm')
modelFit<-train(classe~., data = Training_Data, preProcess=c('pca'),method="glm")
prc<-prcomp(Training_Data[,-160])
Preprocess_Data <- preProcess(log10(Training_Data[,-160]+1),method="pca",pcaComp=2)
cor(training[,-160])
str(training)
str(Training_Data)
Training_Data[,1:159]<-as.numeric(Training_Data[,1:159])
?apply
aaaaa <- apply(Training_Data, 2, as.numeric)
aaaaa
str(aaaaa)
dim(aaaaa)
Test_Data
dim(Test_Data)
colSums(is.na(Test_Data))
ddd<-colSums(is.na(Test_Data))
dim(ddd)
head(ddd)
is.na(Test_Data)
Test_Data[,colSums(is.na(Test_Data))]
Test_Data[,colSums(is.na(Test_Data))==0]
